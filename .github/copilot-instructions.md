ðŸš¦ Universal Copilot TDD Executor (Flutter + Riverpod) â€” With Explicit Integration Testing

Copilot Goal
Autonomously make the Flutter app fully green and validated end-to-end for the feature I provide below, using strict TDD loops and final iOS simulator checks via ios-simulator-mcp.

Operation Mode
â€¢ Fully agentic; do not wait for approvals.
â€¢ Follow Red â†’ Green â†’ Refactor for every sub-behavior.
â€¢ Keep edits minimal and focused; no unrelated features or broad refactors.
â€¢ Constrain all edits to the project repo; preserve style/naming.

Context & Stack
Flutter â€¢ Riverpod (flutter_riverpod, hooks_riverpod) â€¢ http â€¢ flutter_dotenv â€¢ shared_preferences â€¢ Tests: flutter_test, golden_toolkit, integration_test, mocktail.
Prefer provider overrides for time/clock, randomness, env, and persistence in tests. No real network in testsâ€”use mocks/fakes.

â¸»

âœ… Acceptance Criteria (applies to every feature)
â€¢ Testing (Unit â†’ Widget â†’ Integration):
â€¢ Add/adjust failing tests first that fully specify the feature.
â€¢ Use provider overrides & mocks: no real network; no sleeps/long waits.
â€¢ All tests pass locally; eliminate flakiness.
â€¢ Line coverage must be generated on every change: run flutter test --coverage and export lcov to CSV/HTML artifacts. Save to coverage/lcov.info and coverage/coverage.csv (use existing tool/csv converter if present).
â€¢ Integration Testing (explicit):
â€¢ Implement integration_test/_flow_test.dart covering the end-to-end user flow.
â€¢ Use Keys for selection, fake clocks, and provider overrides for env/prefs/services.
â€¢ Save screenshots and logs to artifacts/ios/_flow.png (and logs to artifacts/logs/ if applicable).
â€¢ iOS Simulator (via ios-simulator-mcp):
â€¢ App launches on iPhone simulator.
â€¢ Perform the feature-specific flow using provided Keys.
â€¢ Assert expected widgets/state; capture screenshot to artifacts/ios/_flow.png.
â€¢ Docs:
â€¢ Update README.md if new env flags/usage or test instructions are introduced.
â€¢ No scope creep: implement only what the tests demand.

â¸»

ðŸ”„ TDD Working Agreement (repeat until feature is done)

For each tiny behavior:
1. RED â€” Write/adjust failing tests
â€¢ Unit for pure logic/state machines.
â€¢ Widget for UI state/rendering.
â€¢ Integration for end-to-end flow (navigation, dialogs, persistence).
â€¢ Inject/override clock, RNG, env, prefs, repositories/services.
â€¢ Mock HTTP with mocktail (retry/timeout/caching logic verified deterministically).
2. GREEN â€” Implement the minimum
â€¢ Change as little code as needed to satisfy the failing tests.
â€¢ Avoid speculative abstractions.
3. REFACTOR â€” Improve safely (See Built-In Refactoring Rules below)
â€¢ Run mandatory refactor checklist each cycle; only apply structural changes triggered by rules.
â€¢ No behavior changes without a new failing (RED) test.
4. Run the whole suite
â€¢ flutter test and flutter test integration_test (or flutter drive where driver is used).
â€¢ Then run line coverage: flutter test --coverage; transform lcov.info to CSV via tool/lcov_to_csv.dart and store at coverage/coverage.csv.
â€¢ Fix flakiness immediately (fake clocks > timers; direct triggers > waits).
5. Checkpoint Output (concise)
â€¢ Files changed (paths).
â€¢ Tests added/updated.
â€¢ Test run summary (counts & duration).

Repeat until all acceptance criteria are met.

â¸»

ðŸ›  Built-In Refactoring Rules (Applied During Each REFACTOR Step)
Refactoring is not optional: after every GREEN, evaluate these triggers. Apply only the minimal structural changes required to satisfy them without altering behavior.

Primary Triggers
1. Oversized File: Any production or test file > 500 LOC must be decomposed until each new file â‰¤ 500 LOC unless the domain entity is inherently cohesive. Split by responsibility (state mgmt, UI, adapters, utilities, test fixtures).
2. Repetition: Logical block (â‰¥ 5 lines or same semantic operation) duplicated 3+ times â†’ extract to function, extension, mixin, widget, or test helper.
3. Function Complexity: Function/method > 40 LOC or cyclomatic complexity > 10 (estimate manually if no tooling) â†’ decompose into smaller pure helpers.
4. Widget Responsibility Creep: A widget handling rendering + navigation + side-effects (+ state manipulation) â†’ split by concern (presentational vs controller/provider logic).
5. Test Setup Duplication: Repeated provider overrides / environment bootstrap across 3+ groups â†’ centralize into a test harness (e.g., buildTestApp(), pumpWithOverrides()).
6. Magic Values: Literal strings/numbers used 3+ times across code/tests â†’ promote to clearly named constant/enum.
7. Bloated Parameter Lists: 7+ parameters â†’ refactor into config/data class or value object (immutable preferred) unless trivial.
8. Cross-Layer Leakage: UI directly performing persistence/network logic â†’ move into repository/service/provider layer.
9. Provider Naming Drift: Provider name not reflecting domain concept â†’ rename (maintain backward compatibility only if externally referenced) with tests enforcing new name usage.
10. Side-Effect Timing: Async side-effects embedded in build() or initState without guard â†’ extract to controlled notifier/service with explicit trigger.
11. Unobserved Branches: Conditional branches not covered by tests â†’ add RED test before refactoring branch logic.
12. Dead Code: Unreferenced functions/classes/providers (verified via search) â†’ remove after confirming no reflective usage.
13. Inconsistent Key Usage: Interactive/queried widgets lacking Keys â†’ add deterministic Key constants (avoid random strings).
14. Layer Boundary Breach in Tests: Tests asserting internal implementation details (private fields) instead of observable outputs â†’ rewrite test to use public API before changing code.
15. Logging Noise: Repeated ad-hoc debug prints â†’ centralize behind a logger utility or remove if not essential.

Refactor Process Guard
â€¢ If a trigger applies but refactor risks altering behavior, introduce a protective RED test first to lock expected state/outputs.
â€¢ Keep commit-sized changes small: one structural concern per refactor cycle.
â€¢ Do not introduce new features while refactoring.

Checklist (Run Every Cycle Before Declaring Done)
[ ] Any file > 500 LOC? Split.
[ ] 3+ duplications? Extract.
[ ] Functions > 40 LOC / complex? Split.
[ ] Widgets multi-responsibility? Separate layers.
[ ] Repeated setup in tests? Centralize harness.
[ ] Magic values repeated? Constant/enum.
[ ] Large param lists? Consolidate.
[ ] UI doing side-effects? Move to provider/service.
[ ] Uncovered branches? Add tests.
[ ] Dead code? Remove.
[ ] Missing Keys for tested widgets? Add.
[ ] Logs noisy? Clean.

Testing Impact of Refactors
â€¢ All existing tests must remain green at each refactor step.
â€¢ If coverage for a modified file drops, add focused tests (prefer unit) before proceeding.
â€¢ Ensure extracted helpers remain pure where possible for simpler unit tests.

Documentation
â€¢ Only update README if refactor introduces externally relevant usage changes (e.g., new env var, command, script).

â¸»

ðŸ§ª Test Authoring Rules (always)
â€¢ Unit tests: pure functions/state transitions; verify formatting, boundaries, retries/backoff.
â€¢ Widget tests: Keys on all interactive/observed widgets; pump with fake time/clock.
â€¢ Integration tests: real navigation + provider overrides; no network; stable selectors by Key.
â€¢ Timing: inject fake clock / explicit triggers (e.g., triggerComplete()); never rely on real timeouts.
â€¢ Persistence: in-memory or temp SharedPreferences; clear between tests.
â€¢ Retries/Backoff: verify max retries & terminal failure deterministically via mocks.

â¸»

ðŸ§© Integration Testing â€” Structure & Conventions
â€¢ Location: integration_test/_flow_test.dart
â€¢ Harness:
â€¢ Use IntegrationTestWidgetsFlutterBinding.ensureInitialized().
â€¢ Wrap app boot with provider overrides (env/prefs/services/clock/RNG).
â€¢ Ensure WidgetsFlutterBinding.ensureInitialized() where necessary for plugins.
â€¢ Selectors: use Key(â€™â€¦â€™) for all tappable/asserter widgets.
â€¢ Clock control: inject fake clock or expose deterministic triggers to avoid pumpAndSettle flakiness.
â€¢ Artifacts: save at least one screenshot â†’ artifacts/ios/_flow.png. Also attach coverage artifacts (coverage/lcov.info, coverage/coverage.csv) for the run.
â€¢ Isolation: reset prefs/mocks between tests; avoid shared state across tests.

â¸»

ðŸ“± iOS Simulator Validation (generic flow)
â€¢ Boot simulator (e.g., iPhone 16 Pro).
â€¢ Wait for main title Key (e.g., Key(â€˜app_titleâ€™)).
â€¢ Perform the feature-specific sequence using Keys from the Feature Slot.
â€¢ Assert final UI state; save screenshot to artifacts/ios/_flow.png.

â¸»

ðŸ§­ Guardrails & Prohibited Actions
â€¢ No real HTTP calls in tests.
â€¢ No arbitrary waits/sleeps; use fake time or direct triggers.
â€¢ No large refactors or cross-cutting style changes beyond explicit refactor triggers.
â€¢ Keep changes within the project; maintain existing naming/style.
â€¢ Refactors must adhere to Built-In Refactoring Rules section.

â¸»

ðŸ“Š Final Output (always provide)
â€¢ Test results summary (counts, pass time).
â€¢ List of modified files with brief rationale.
â€¢ iOS simulator validation steps executed and screenshot path.
â€¢ Coverage summary (total line coverage 95%+, key package/file highlights) with paths to artifacts.